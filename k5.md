# Kandinsky-5

Kijai's wip [wf](screenshots/kijai-wip-k5.png).
Kijai's ComfyUI clone with [kandinsky5](https://github.com/kijai/ComfyUI/tree/kandinsky5) branch - the preferred implemenation of the model in ComfyUI.
There is an outstanding [PR](https://github.com/comfyanonymous/ComfyUI/pull/10988) to merge it.
Includes latest [optimization](https://github.com/comfyanonymous/ComfyUI/commit/73f5649196f472d3719e2e7513e0a9d029cc3e38) reduing VRAM usaby by VAE by around 40%.
[DiT-Extrapoloatin](https://github.com/thu-ml/DiT-Extrapolation) formerly known as RifleX is partially implemented.

> that's how the model works for I2V, the first latent is just noise and it has to be replaced by the actual input image before decoding

Experiments with running the model in ComfyUI on consumer hardware are in their initial stages.
There currently exist two work-in-progress implementations:

- [GH:Ada123-a/ComfyUI-Kandinsky](https://github.com/Ada123-a/ComfyUI-Kandinsky)
- [GH:maybleMyers/kandinsky5](https://github.com/maybleMyers/kandinsky5)

Experiments suggest it is possible to generate longer than 10 sec clips, say 15 sec without looping or obvious quality problems.

> some parts of the model need to be kept in fp32, the norms and embeddings etc. This is the mixed i2v model: https://huggingface.co/maybleMyers/kan/blob/main/diffusion_pytorch_model_i2v_pro_fp32_and_bf16.safetensors

[kijai/ComfyUI-KJNodes](https://github.com/kijai/ComfyUI-KJNodes) contains `NABLA Attention KJ` node: "only useful if you go 10s or high res"; "Docs mention NABLA dimensions must be divisible by 128"

"Flex attention" is mentioned as an alternative (?) to Nabla.
